{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kears\n",
    "\n",
    "- Keras의 개요\n",
    "    - 파이썬으로 구현된 쉽고 간결한 딥러닝 라이브러리\n",
    "    - 내부적으로 텐서플로우 엔진이 구동되지만 직관적인 API로 쉽게 딥러닝 실험을 할 수 있도록 지원함\n",
    "    \n",
    "- Keras의 주요 특징\n",
    "    - 모듈화(Modularity) : 독립적인 모듈들을 조합하여 구현\n",
    "    - 최소주의(Minialism) : 각 모듈은 짧고 간결\n",
    "    - 쉬운 확장성 : 클래스나 함수로 모듈을 쉽게 추가할 수 있음\n",
    "    - 파이썬 기반 : 별도의 설정이 필요없음\n",
    "    \n",
    "- keras를 이용한 실습 순서\n",
    "    - 데이터셋 생성\n",
    "        - 데이터로부터 학습용, 검증용 데이터셋 구분\n",
    "        - 딥러닝 모델의 학습 및 검증을 할 수 있도록 케라스에서 요구하는 형태로 변환을 해야 함\n",
    "    - 모델 구성\n",
    "        - Sequence 모델을 생성한 후 필요한 Layer를 추가하여 구성\n",
    "    - 모델 학습과정 설정\n",
    "        - 손실 함수 및 최적화 방법 정의\n",
    "        - 모델 컴파일\n",
    "    - 모델 학습\n",
    "        - 학습용 데이터를 이용하여 모델 학습\n",
    "    - 학습과정 출력\n",
    "        - 학습 시 학습용, 검증용 데이터셋의 손실 및 정확도 측정\n",
    "    - 모델 평가\n",
    "        - 검증용 데이터셋으로 학습한 모델을 평가\n",
    "    - 새로운 데이터 사용하여 값을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras 기반의 회귀분석 예제\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 한글 처리를 위해 폰트 설정\n",
    "rc('font', family='AppleGothic')\n",
    "# 음수 부호가 깨지지 않도록 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 주택가격 예측 : 회귀분석\n",
    "# 회귀분석 : 연속적인 값을 예측\n",
    "# 예) 과거 기상 데이터를 입력하여 내일의 기온을 예측\n",
    "# 보스턴 주택 가격 데이터셋\n",
    "# 1970년 중반 보스턴 외곽 지역의 범죄율, 지방세율 등의 데이터로 주택 가격 예측\n",
    "# 샘플 갯수 : 506개(학습용 404개, 검증용 102개)\n",
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습용 404개, 검증용 102개, 13개의 변수\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 종속변수 : 주택의 가격(천달러 단위)\n",
    "train_targets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "# 상이한 스케일을 가진 값을 신경망에 입력하면 예측 정확도가 떨어질 수 있음\n",
    "# 데이터 정규화 : 각 변수에 대해서 표준 편차가 1이 되도록 평균을 빼고 표준 편차로 나눈다.\n",
    "# 평균값을 빼고\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "test_data -= mean\n",
    "\n",
    "# 표준편차로 나눈다\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "        -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "         1.14850044,  0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, -0.25683275, -1.21518188,\n",
       "         1.89434613, -1.91036058,  1.24758524, -0.85646254, -0.34843254,\n",
       "        -1.71818909,  0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , -0.25683275,  0.62864202,\n",
       "        -1.82968811,  1.11048828, -1.18743907,  1.67588577,  1.5652875 ,\n",
       "         0.78447637,  0.22061726, -1.30850006],\n",
       "       [-0.40149354, -0.48361547, -0.86940196, -0.25683275, -0.3615597 ,\n",
       "        -0.3245576 , -1.23667187,  1.10717989, -0.51114231, -1.094663  ,\n",
       "         0.78447637,  0.44807713, -0.65292624],\n",
       "       [-0.0056343 , -0.48361547,  1.0283258 , -0.25683275,  1.32861221,\n",
       "         0.15364225,  0.69480801, -0.57857203,  1.67588577,  1.5652875 ,\n",
       "         0.78447637,  0.3898823 ,  0.26349695]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수 : 입력데이터를 적절하게 처리하여 출력데이터를 만들어내는 함수\n",
    "# input_data -> {activation function} -> output data\n",
    "# 활성화 함수의 종류 : 탄젠트(thanh) 함수, 시그모이드(sigmoid) 함수, ReLU 함수\n",
    "# 탄젠트 함수나 시그모이드 함수보다 학습시간이 빨라서 최근에는 ReLU(Rectified Linear Unit)가 많이 사용되고 있음\n",
    "from keras import models\n",
    "from keras import layers\n",
    "# 64개의 노드를 가진 은닉층 2개의 신경망\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    # relu\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                          input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # 출력층(1개의 노드, 하나의 값을 예측하는 회귀분석의 경우 활성화 함수가 없는 선형층을 사용함)\n",
    "    model.add(layers.Dense(1))\n",
    "    # mse 손실 함수를 사용하여 컴파일\n",
    "    # mse : 평균 제곱 오차(mean squared error) - 예측값과 실제값의 거리의 제곱\n",
    "    # mae : 평균 절대 오차, 예측값과 실제값의 거리의 절대값\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold\n",
      "WARNING:tensorflow:From /Users/kyeongmin/anaconda3/envs/django/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kyeongmin/anaconda3/envs/django/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 202.4445 - mean_absolute_error: 10.7736\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 30.2679 - mean_absolute_error: 3.8343\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 21.2854 - mean_absolute_error: 3.1729\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 18.2128 - mean_absolute_error: 2.8948\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 16.5866 - mean_absolute_error: 2.6596\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 15.4178 - mean_absolute_error: 2.5639\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.1868 - mean_absolute_error: 2.5340\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.8043 - mean_absolute_error: 2.4205\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.3085 - mean_absolute_error: 2.4052\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.1970 - mean_absolute_error: 2.3699\n",
      "101/101 [==============================] - 0s 394us/step\n",
      "1 fold\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 218.3035 - mean_absolute_error: 11.2175\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 28.6035 - mean_absolute_error: 3.5316\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 19.9775 - mean_absolute_error: 3.0044\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 17.6487 - mean_absolute_error: 2.6652\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 15.0021 - mean_absolute_error: 2.5575\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.0342 - mean_absolute_error: 2.4930\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.9582 - mean_absolute_error: 2.3900\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.1947 - mean_absolute_error: 2.3567\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.3848 - mean_absolute_error: 2.2553\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.4406 - mean_absolute_error: 2.1760\n",
      "101/101 [==============================] - 0s 484us/step\n",
      "2 fold\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 211.1854 - mean_absolute_error: 10.7182\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 30.7728 - mean_absolute_error: 3.8542\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 20.2583 - mean_absolute_error: 3.0534\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 16.0863 - mean_absolute_error: 2.7460\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 14.0141 - mean_absolute_error: 2.5691\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.6469 - mean_absolute_error: 2.3883\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.4117 - mean_absolute_error: 2.3675\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 10.6047 - mean_absolute_error: 2.2779\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 9.9501 - mean_absolute_error: 2.2226\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 10.2305 - mean_absolute_error: 2.2341\n",
      "101/101 [==============================] - 0s 1ms/step\n",
      "3 fold\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 209.4821 - mean_absolute_error: 10.9759\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 32.9441 - mean_absolute_error: 3.8820\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 22.8204 - mean_absolute_error: 3.0776\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 18.6670 - mean_absolute_error: 2.7171\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 15.5478 - mean_absolute_error: 2.5540\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.4181 - mean_absolute_error: 2.4546\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 12.8529 - mean_absolute_error: 2.3278\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.3769 - mean_absolute_error: 2.2112\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.5413 - mean_absolute_error: 2.1713\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 11.2853 - mean_absolute_error: 2.2270\n",
      "101/101 [==============================] - 0s 949us/step\n"
     ]
    }
   ],
   "source": [
    "# k-fold 교차 검증\n",
    "# 샘플 갯수가 많지 않으므로 학습용 데이터의 크기가 매우 작아지게 됨(약 100개의 샘플)\n",
    "# 그러면 샘플링할 때마다 검증용 데이터셋의 점수가 크게 달라지게 됨\n",
    "# 이렇게 되면 모델의 신뢰성이 떨어질 수 있음\n",
    "# 데이터건수가 적은 경우 k-fold(k-겹) 교차 검증 사용\n",
    "# 데이터를 k개의 분할(fold, 폴드)로 나누고(일반적ㅇ로 4 또는 5)\n",
    "# k개의 모델을 각각 만들어 k - 1 개의 세트로 학습시키고 나머지는 1개의 세트로 검증하는 방법\n",
    "# 모델의 예측도 점수는 k개의 점수의 평균으로 처리\n",
    "import numpy as np\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 10\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print(i, 'fold')\n",
    "    # 검증용 데이터 준비 : k번째 분할\n",
    "    val_data = train_data[i*num_val_samples:(i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples:(i+1) * num_val_samples]\n",
    "    \n",
    "    # 학습용 데이터 준비 : 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "        train_data[(i+1)*num_val_samples:]], axis=0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "        train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "    \n",
    "    # 케라스 모델 구성\n",
    "    model = build_model()\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "             epochs = num_epochs, batch_size=1, verbose=1)\n",
    "    \n",
    "    # 검증용 데이터로 모델 평가\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4877246677285374,\n",
       " 2.5931055947105484,\n",
       " 2.5399238567541143,\n",
       " 2.8044408370952794]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.60629873907212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)\n",
    "# 2600달러 정도 차이가 남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
